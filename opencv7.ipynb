{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deefb596-695e-4493-b9ed-fbcbb74009f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd9e92-b577-4781-bb54-899562bfb4db",
   "metadata": {},
   "source": [
    "## background removing from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b35e0de1-214f-47fc-8523-adf069f5b9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "algo1 = cv2.createBackgroundSubtractorKNN()\n",
    "algo2 = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while True:\n",
    "    r,f = cap.read()\n",
    "    if r == True:\n",
    "        f = cv2.resize(f,(500,600))\n",
    "        r1 = algo1.apply(f)\n",
    "        r2 = algo2.apply(f)\n",
    "        cv2.imshow(\"window1\", r1)\n",
    "        cv2.imshow(\"window2\",r2)\n",
    "        cv2.imshow(\"ws\",f)\n",
    "        if cv2.waitKey(25) & 0xff == ord(\"p\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84434bc-5fa6-4459-8c7e-e5b6c4323abf",
   "metadata": {},
   "source": [
    "## object tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15c66de5-cc17-4618-ab63-a5d7d94a88cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "r,f = cap.read()\n",
    "x,y,w,h =220, 150, 120, 350 ##  Sets a hardcoded rectangle (x, y, width, height) as the region of interest (ROI).\n",
    "t = (x,y,w,h)  ## track\n",
    "roi = f[y:y+h, x:x+w]\n",
    "hsv_roi = cv2.cvtColor(roi,cv2.COLOR_BGR2HSV)     ## Converts it to HSV color space (which is better for color segmentation\n",
    "mask = cv2.inRange(hsv_roi, np.array((0.,60.,32.)), np.array((180.,255.,255.)))  # filter out irrelevant background\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[100],[0,180])    ## filter it using histogram\n",
    "##In object tracking, we want to recognize the object in future frames. \n",
    "##One simple and effective way is to track based on color. \n",
    "##A histogram gives us a statistical representation of color distribution.\n",
    "\n",
    "\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)      ## we have normalised it\n",
    "\n",
    "tr = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,1)  ## Termination criteria when to stop\n",
    "##cv2.TERM_CRITERIA_EPS – stop the algorithm if the movement of the window is smaller than epsilon.\n",
    "\n",
    "##cv2.TERM_CRITERIA_COUNT – stop after a maximum number of iterations.\n",
    "\n",
    "while True:\n",
    "    r,f = cap.read()\n",
    "    if r == True:\n",
    "        f = cv2.resize(f,(500,600))\n",
    "        hsv_f = cv2.cvtColor(f, cv2.COLOR_BGR2HSV)\n",
    "        d = cv2.calcBackProject([hsv_f],[0],roi_hist,[0,180],1)  ## here we track the image\n",
    "        r,tp = cv2.meanShift(d,t,tr)              ## it basically gives us the coordinate of the shifted image\n",
    "        x,y,w,h= tp\n",
    "        final = cv2.rectangle(f,(x,y),(x+w, y+h),(0,0,255),4)\n",
    "        cv2.imshow(\"window\", final)\n",
    "        if cv2.waitKey(25) & 0xff == ord(\"p\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f5f5e4-6006-493a-8c2a-3435f5499e73",
   "metadata": {},
   "source": [
    "## Detect the corner points   cornerHarris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ceab62cd-acce-4341-8e83-0c49f0fc07d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"img1.jpg\")\n",
    "gr = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gr = np.float32(gr)  ## required float input\n",
    "\n",
    "res = cv2.cornerHarris(gr,2,3,0.04)  ##(img, blocksize, mat.size, parameter) res: A matrix of the same size as the image, \n",
    "                        ##where corner strength is stored in each pixel. Higher values mean more \"corner-like\".\n",
    "\n",
    "res = cv2.dilate(res,None)  ## its a filter enhance the corner points\n",
    "img[res>0.01*res.max()]=  [0,0,255]   ## strong corners where val is 1% of max value\n",
    "\n",
    "cv2.imshow(\"window\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759cf32a-27e2-49af-88a9-be6b9094d70b",
   "metadata": {},
   "source": [
    "## corner detection using shi-tomasi corner detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08fefa7a-545e-4ab1-b934-626708a159ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[316 446]]\n",
      "\n",
      " [[172 507]]\n",
      "\n",
      " [[214 261]]\n",
      "\n",
      " [[288 345]]\n",
      "\n",
      " [[180 442]]\n",
      "\n",
      " [[195 121]]\n",
      "\n",
      " [[157 111]]\n",
      "\n",
      " [[167 403]]\n",
      "\n",
      " [[166  30]]\n",
      "\n",
      " [[ 38 489]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"img1.jpg\")\n",
    "gr = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cr = cv2.goodFeaturesToTrack(gr, 10, 0.01, 20) ### img, maxcorner_points, qualityLevel, mindistance,\n",
    "\n",
    "cr = np.int64(cr)                 ## gives us float values -> to int\n",
    "print(cr)\n",
    "\n",
    "for i in cr:\n",
    "    x,y = i.ravel()                        ## convert data in 1D\n",
    "    cv2.circle(img, (x,y), 5, (0,0,255), -1)  ## -1 solid thickness\n",
    "    \n",
    "\n",
    "\n",
    "cv2.imshow(\"window\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e7437a-0fbd-453c-a8d9-5c5df305956a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
